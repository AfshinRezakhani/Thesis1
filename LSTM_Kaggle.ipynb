{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcyuBS0wcHNGN/kPKKV0xn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfshinRezakhani/Thesis1/blob/main/LSTM_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP2hwWdsEZWZ",
        "outputId": "740b6f75-0988-4b3e-bf3c-e093ce88561b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 0.3797\n",
            "Epoch 2/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.2215\n",
            "Epoch 3/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.2307\n",
            "Epoch 4/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.2193\n",
            "Epoch 5/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9426 - loss: 0.2206\n",
            "Epoch 6/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9399 - loss: 0.2279\n",
            "Epoch 7/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.2252\n",
            "Epoch 8/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.2225\n",
            "Epoch 9/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.2329\n",
            "Epoch 10/10\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.2251\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Accuracy: 0.9437\n",
            "F1-Score: 0.9710\n",
            "True Positives (TP): 6185\n",
            "True Negatives (TN): 0\n",
            "False Positives (FP): 369\n",
            "False Negatives (FN): 0\n",
            "False Positive Rate (FPR): 1.0000\n",
            "False Negative Rate (FNR): 0.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/Kaggle.csv\"  # Ensure this file is uploaded to Colab\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['A'])\n",
        "y = df['A']\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape data for LSTM input\n",
        "X_train = X_train.reshape(-1, 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(-1, 1, X_test.shape[1])\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(1, X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Compute metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f_score = f1_score(y_test, y_pred)\n",
        "\n",
        "# Compute confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Compute False Positive Rate (FPR) and False Negative Rate (FNR)\n",
        "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1-Score: {f_score:.4f}\")\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
        "print(f\"False Negative Rate (FNR): {fnr:.4f}\")\n"
      ]
    }
  ]
}